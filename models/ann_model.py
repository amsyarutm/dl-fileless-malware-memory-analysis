# Import necessary libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

# List files in the directory (optional, for verification)
import os
for dirname, _, filenames in os.walk('D:/Cybersecurity/KerasNLP'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# Load the data
df = pd.read_csv('D:/Cybersecurity/KerasNLP/MalwareMemoryDump.csv')

# Basic data exploration
print("First five rows of the dataframe:")
print(df.head())

print("\nLast five rows of the dataframe:")
print(df.tail())

print("\nDataframe information:")
print(df.info())

print("\nDescriptive statistics:")
print(df.describe().T)  # Transposed for better readability

# Data profiling function
def data_profiling(df):
    data_profile = []
    columns = df.columns
    for col in columns:
        dtype = df[col].dtypes
        nunique = df[col].nunique()
        null = df[col].isnull().sum()
        duplicates = df[col].duplicated().sum()
        data_profile.append([col, dtype, nunique, null, duplicates])
    data_profile_finding = pd.DataFrame(data_profile)
    data_profile_finding.columns = ['column', 'dtype', 'nunique', 'null', 'duplicates']
    return data_profile_finding

# Print data profiling
print("Data Profiling:")
print(data_profiling(df))

# Null values count
print("\nNull values in each column:")
print(df.isnull().sum())

# Value counts for 'ClassTypeName' column
print("\nValue counts for 'ClassType':")
print(df['ClassType'].value_counts())

# Value counts for 'SubType' column
print("\nValue counts for 'SubType':")
print(df['SubType'].value_counts())  # Can add .head(n) to limit the output

# EDA
numeric_features = [i for i in df.columns if df[i].dtype != 'O']
categorical_features = [i for i in df.columns if df[i].dtype == 'O']

print(len(numeric_features))

# Correlation
# Excluding non-numeric columns for correlation
numerical_df = df.select_dtypes(include=[np.number])

# Plotting the heatmap
sns.set(rc={'figure.figsize': (45, 25)})
sns.heatmap(numerical_df.corr(), vmin=-1, vmax=1, cmap="PiYG", annot=True)
plt.show()

plt.figure(figsize=(25, 10))
sns.countplot(data=df, x='SubType', palette='Set2')
plt.show()

plt.figure(figsize=(25, 10))
sns.countplot(data=df, x='ClassType', palette='Set2')
plt.title("Distribution of Class Types")
plt.show()

# Feature Engineering

#### Removing the column which have no corelation with other data values
# - pslist_nprocs64bit
# - handles_nport
# - psxview_not_in_pslist_false_avg
# - svcscan_interactive_process_services 
# - callbacks_ngeneric
# - callbacks_nanonymous
# - Raw type
# - Sub Type

# Dropping specified columns
df = df.drop([
    'pslist_nprocs64bit',
    'handles_nport',
    'psxview_not_in_pslist_false_avg',
    'svcscan_interactive_process_services',
    'callbacks_ngeneric',
    'callbacks_nanonymous',
    'Raw_Type',
    'SubType'
], axis=1)

# Displaying first few rows to confirm the changes
print("First five rows after dropping columns:")
print(df.head())

# Splitting the dataframe into features (X) and target (y)
x = df.drop('ClassType', axis=1).values  # Features: All columns except 'ClassType'
y = df['ClassType'].values  # Target: 'ClassType' column

# Printing the shape of x
print("\nShape of feature matrix (x):", x.shape)

# Label Encoding the target variable
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y = le.fit_transform(y)
print("Encoded target variable:", y)

# Train-Test Split & Feature Scaling
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)
sc = StandardScaler()
x_train = sc.fit_transform(x_train)
x_test = sc.transform(x_test)

print(x_train.shape)
print(x_test.shape)

# Model Building With Deep Learning ANN

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

classifier = Sequential()

classifier.add(Dense(64, activation='relu'))
classifier.add(Dense(128, activation='relu'))
classifier.add(Dense(128, activation='relu'))
classifier.add(Dense(3, activation='softmax'))  # Output layer for 3 categories in ClassType

# Compile the model
classifier.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Model Training
model = classifier.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=20, batch_size=32)

# Plotting Training & Validation Accuracy and Losses
plt.figure(figsize=(25, 10))
plt.plot(model.history['loss'])
plt.plot(model.history['val_loss'])
plt.title("Losses")
plt.xlabel('epoch')
plt.legend(['Training', 'Validation'])
plt.show()

plt.figure(figsize=(25, 10))
plt.plot(model.history['accuracy'])
plt.plot(model.history['val_accuracy'])
plt.title("Training and validation accuracy")
plt.xlabel('epoch')
plt.legend(['Training', 'Validation'])
plt.show()

# Performance Evaluation

# Import necessary libraries
from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, auc

# Predicting the Test set results
y_pred = classifier.predict(x_test)
y_pred_labels = np.argmax(y_pred, axis=1)

# Calculate confusion matrix
cm = confusion_matrix(y_test, y_pred_labels)
print("Confusion Matrix:")
print(cm)

# Generate classification report
report = classification_report(y_test, y_pred_labels, target_names=['Benign', 'Malware', 'Fileless'])
print(report)

# Calculate ROC AUC
roc_auc = roc_auc_score(y_test, y_pred, multi_class='ovr')
print(f"ROC AUC: {roc_auc}")

# Plot ROC Curve
fpr = {}
tpr = {}
roc_auc = {}

for i in range(3):
    fpr[i], tpr[i], _ = roc_curve(y_test, y_pred[:, i], pos_label=i)
    roc_auc[i] = auc(fpr[i], tpr[i])

plt.figure()
for i in range(3):
    plt.plot(fpr[i], tpr[i], lw=2, label=f'ROC curve of class {i} (area = {roc_auc[i]:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()
